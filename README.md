# LangGraph Agentic RAG

Un sistema de **Agentic Retrieval-Augmented Generation (RAG)** construido con LangGraph que combina recuperaciÃ³n de documentos vectoriales y bÃºsqueda web para generar respuestas fundamentadas y precisas a preguntas de los usuarios.

## ğŸ¯ DescripciÃ³n

Este proyecto implementa un agente inteligente que decide automÃ¡ticamente si responder desde documentos internos vectorizados o desde bÃºsquedas web en tiempo real. Incluye validaciÃ³n de relevancia, detecciÃ³n de alucinaciones y evaluaciÃ³n de utilidad de las respuestas.

## âœ¨ CaracterÃ­sticas

- **Ruteo Inteligente**: Decide entre vectorstore interno y bÃºsqueda web segÃºn el contexto de la pregunta
- **ValidaciÃ³n de Relevancia**: EvalÃºa si los documentos recuperados son relevantes para la pregunta
- **DetecciÃ³n de Alucinaciones**: Verifica que las respuestas estÃ©n fundamentadas en las fuentes
- **EvaluaciÃ³n de Utilidad**: Confirma que la respuesta aborda correctamente la pregunta
- **BÃºsqueda Web Integrada**: Complementa informaciÃ³n con Tavily cuando es necesario
- **Persistencia de Datos**: Usa ChromaDB para almacenar documentos vectorizados

## ğŸ—ï¸ Arquitectura

El sistema implementa un flujo de trabajo con nodos especializados:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Router    â”‚ Decide: vectorstore o websearch
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â†’ RETRIEVE â†’ GRADE_DOCUMENTS â†’ DECIDE_TO_GENERATE
       â”‚                                    â”‚
       â”‚                                    â”œâ”€â†’ GENERATE â†’ GRADE_GENERATION
       â”‚                                    â”‚                â”‚
       â”‚                                    â”‚                â”œâ”€â†’ END (useful)
       â”‚                                    â”‚                â”œâ”€â†’ WEBSEARCH (not useful)
       â”‚                                    â”‚                â””â”€â†’ END (not supported)
       â”‚                                    â”‚
       â””â”€â†’ WEBSEARCH â†’ GENERATE â†’ END
```

### Nodos del Grafo

- **Router**: Decide quÃ© fuente de datos usar (vectorstore o web search)
- **Retrieve**: Recupera documentos relevantes del vectorstore
- **Grade Documents**: EvalÃºa la relevancia de los documentos recuperados
- **Web Search**: Realiza bÃºsqueda web con Tavily
- **Generate**: Genera la respuesta final usando el contexto disponible
- **Grade Generation**: Valida la calidad y fundamentaciÃ³n de la respuesta

## ğŸš€ InstalaciÃ³n

### Requisitos

- Python >= 3.10
- Poetry (para gestiÃ³n de dependencias)

### Pasos

1. Clona el repositorio:
```bash
git clone https://github.com/alejandroSanchezCaceres/langgraph-agentic-rag.git
cd langgraph-agentic-rag
```

2. Instala las dependencias:
```bash
poetry install
```

3. Configura las variables de entorno:
```bash
cp .env_example .env
```

Edita el archivo `.env` con tus API keys:
```
OPENAI_API_KEY=tu_key_aqui
LANGCHAIN_API_KEY=tu_key_aqui
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=langgraph-agentic-rag
TAVILY_API_KEY=tu_key_aqui
```

4. (Opcional) Ejecuta el script de ingesta para cargar documentos iniciales:
```bash
poetry run python ingestion.py
```

## ğŸ“– Uso

### Ejecutar el Agente

```bash
poetry run python main.py
```

### Personalizar las Preguntas

Edita `main.py` y descomenta/modifica las preguntas de ejemplo:

```python
# Pregunta que usa documentos internos
result = app.invoke(input={"question": "What is agent memory?"})

# Pregunta que requiere bÃºsqueda web
result = app.invoke(input={"question": "CÃ³mo termino el IPC de bolsa mexicana de valores el dÃ­a de hoy?"})

# Pregunta en espaÃ±ol
result = app.invoke(input={"question": "QuÃ© me puedes decir de los agentes de inteligencia artificial?"})
```

## ğŸ§© Componentes Principales

### Chains (Cadenas de Procesamiento)

- **Router**: Rutea preguntas a la fuente de datos apropiada
- **Retrieval Grader**: EvalÃºa relevancia de documentos
- **Hallucination Grader**: Detecta alucinaciones en respuestas
- **Answer Grader**: Verifica que la respuesta conteste la pregunta
- **Generation**: Genera respuestas fundamentadas en contexto

### Nodos

- **retrieve**: RecuperaciÃ³n de documentos desde ChromaDB
- **grade_documents**: EvaluaciÃ³n de relevancia de documentos
- **web_search**: BÃºsqueda web con Tavily
- **generate**: GeneraciÃ³n de respuestas con LLM

## ğŸ”§ ConfiguraciÃ³n

### Modelo LLM

Por defecto usa `gpt-4o-mini`. Puedes modificarlo en los archivos de chains:

```python
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
```

### Vectorstore

Usa ChromaDB con persistencia local. ConfiguraciÃ³n en `ingestion.py`:

```python
retriever_vector = Chroma(
    collection_name="rag-chroma",
    embedding_function=OpenAIEmbeddings(),
    persist_directory="./"
).as_retriever()
```

### Documentos Iniciales

Por defecto carga documentos de:
- Agentes de IA (Lilian Weng)
- Prompt Engineering
- Adversarial Attacks en LLMs

Puedes modificar la lista de URLs en `ingestion.py`.

## ğŸ“Š Validaciones y Control de Calidad

El sistema implementa tres niveles de validaciÃ³n:

1. **Relevancia de Documentos**: Si no son relevantes, busca en la web
2. **FundamentaciÃ³n**: Si la respuesta no estÃ¡ basada en documentos, termina
3. **Utilidad**: Si no contesta la pregunta, intenta con bÃºsqueda web

## ğŸ› ï¸ Desarrollo

### Estructura del Proyecto

```
langgraph-agentic-rag/
â”œâ”€â”€ graph/                    # Nodos y configuraciÃ³n del grafo
â”‚   â”œâ”€â”€ chains/              # Cadenas de procesamiento
â”‚   â”‚   â”œâ”€â”€ router.py
â”‚   â”‚   â”œâ”€â”€ retrieval_grader.py
â”‚   â”‚   â”œâ”€â”€ hallucination_grader.py
â”‚   â”‚   â”œâ”€â”€ answer_grader.py
â”‚   â”‚   â””â”€â”€ generation.py
â”‚   â”œâ”€â”€ nodes/               # Nodos del grafo
â”‚   â”‚   â”œâ”€â”€ retrieve.py
â”‚   â”‚   â”œâ”€â”€ grade_documents.py
â”‚   â”‚   â”œâ”€â”€ web_search.py
â”‚   â”‚   â””â”€â”€ generate.py
â”‚   â”œâ”€â”€ graph.py            # ConstrucciÃ³n del grafo
â”‚   â”œâ”€â”€ state.py            # Estado del grafo
â”‚   â””â”€â”€ consts.py           # Constantes
â”œâ”€â”€ ingestion.py            # Script de ingesta de documentos
â”œâ”€â”€ main.py                 # Punto de entrada
â”œâ”€â”€ logger.py               # Utilidades de logging
â”œâ”€â”€ pyproject.toml          # ConfiguraciÃ³n Poetry
â””â”€â”€ README.md               # Este archivo
```

### Ejecutar Pruebas

```bash
poetry run pytest
```

### Formateo de CÃ³digo

```bash
poetry run black .
poetry run isort .
```

## ğŸ“ Licencia

Este proyecto es de uso educativo y de investigaciÃ³n.

## ğŸ‘¤ Autor

**Gualberto Alejandro Sanchez Caceres**
- Email: sanchezga@globalhitss.com

## ğŸ™ Agradecimientos

- [LangGraph](https://github.com/langchain-ai/langgraph) - Framework para agentes AI
- [LangChain](https://github.com/langchain-ai/langchain) - Framework para aplicaciones LLM
- [ChromaDB](https://www.trychroma.com/) - Base de datos vectorial
- [Tavily](https://tavily.com/) - API de bÃºsqueda web para AI

## ğŸ”— Referencias

- [Agentes de IA - Lilian Weng](https://lilianweng.github.io/posts/2023-06-23-agent/)
- [Prompt Engineering - Lilian Weng](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)
- [Adversarial Attacks on LLMs - Lilian Weng](https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/)

